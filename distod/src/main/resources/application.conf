distod {

  // actor system name used in remoting
  system-name = "distod"
  // role of the actor system in the cluster (either leader or follower)
  system-role = "leader"

  input {
    // filepath pointing to a dataset that is read and analyzed for ODs
    path = "data/flight_500_28c.csv"
//    path = "data/flights_20_500k.csv"
    // if the input file has a header
    has-header = yes

    // restrict number of columns
//    max-columns = 10
    // restrict number of rows
//    max-rows = 1000

  }

  // filepath where the result is stored
  output-file = "data/results.txt"
  // should the results also be printed to console?
  output-to-console = off
  // number of dependencies that are grouped into one message to be sent to the result collector by the proxies
  result-batch-size = 50

  // network configuration of current node
  host = "127.0.0.1"
  port = 7878

  // remote address of leader node
  leader-host = ${distod.host}
  leader-port = ${distod.port}

  // limit the number of workers spawned by this node
  // actual: #workers = min(#cores, max-workers)
  // this does also limit the max number of threads for the cpu-bound-task-dispatcher
  max-workers = 64

  // Dispatcher used for CPU-bound task processing to free up default dispatcher from this heavy load.
  // A step towards making nodes in a cluster responsive (allow scheduled cluster heartbeats and custom gossip)
  cpu-bound-tasks-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    // Configuration for the thread pool
    thread-pool-executor {
      // Keep alive time for threads
      keep-alive-time = 20s

      // core pool: number of threads spawned when queue is not full yet (we limited the queue to be of size 1)
      core-pool-size-min = 1
      core-pool-size-factor = 0.5 // ceil(available processors * factor)
      core-pool-size-max = 32

      // max number of threads (thread capacitiy)
      max-pool-size-min = 1
      max-pool-size-factor = 1.0
      max-pool-size-max = ${distod.max-workers} // 64

      // Specifies the bounded capacity of the task queue (< 1 == unbounded)
      task-queue-size = 1
      task-queue-type = "linked"
    }
    # Throughput defines the maximum number of messages to be
    # processed per actor before the thread jumps to the next actor.
    # Set to 1 for as fair as possible.
    throughput = 2
  }
}

akka {

  // use SLF4J logger
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "INFO"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  log-config-on-start = off

  actor {
    provider = cluster

    // In addition to the default there is akka.actor.StoppingSupervisorStrategy.
    guardian-supervisor-strategy = "akka.actor.DefaultSupervisorStrategy"

    serializers {
      java = "akka.serialization.JavaSerializer"
      bytes = "akka.serialization.ByteArraySerializer"
      primitive-long = "akka.serialization.LongSerializer"
      primitive-int = "akka.serialization.IntSerializer"
      primitive-string = "akka.serialization.StringSerializer"
      primitive-bytestring = "akka.serialization.ByteStringSerializer"
      primitive-boolean = "akka.serialization.BooleanSerializer"
//      kryo = "com.twitter.chill.akka.AkkaSerializer"
      jackson-json = "akka.serialization.jackson.JacksonJsonSerializer"
      jackson-cbor = "akka.serialization.jackson.JacksonCborSerializer"
    }

    serialization-bindings {
      "[B" = bytes
      "java.io.Serializable" = none
//      "scala.Serializable" = none
      // Java Serializer is by default used for exceptions and will by default
      // not be allowed to be serialized, but in certain cases they are replaced
      // by `akka.remote.serialization.ThrowableNotSerializableException` if
      // no specific serializer has been defined:
      // - when wrapped in `akka.actor.Status.Failure` for ask replies
      // - when wrapped in system messages for exceptions from remote deployed child actors
      "java.lang.Throwable" = none

      "java.lang.String" = primitive-string
      "akka.util.ByteString$ByteString1C" = primitive-bytestring
      "akka.util.ByteString$ByteString1" = primitive-bytestring
      "akka.util.ByteString$ByteStrings" = primitive-bytestring
      "java.lang.Long" = primitive-long
      "scala.Long" = primitive-long
      "java.lang.Integer" = primitive-int
      "scala.Int" = primitive-int
      "java.lang.Boolean" = primitive-boolean
      "scala.Boolean" = primitive-boolean

      "com.github.codelionx.distod.Serialization$JsonSerializable" = jackson-json
      "com.github.codelionx.distod.Serialization$CborSerializable" = jackson-cbor

//      "akka.stream.impl.streamref.StreamRefsProtocol$CumulativeDemand" = java
//      "akka.stream.impl.streamref.StreamRefsProtocol$OnSubscribeHandshake" = java
//      "akka.stream.impl.streamref.StreamRefsProtocol$RemoteStreamFailure" = java
//      "akka.stream.impl.streamref.StreamRefsProtocol$SequencedOnNext" = java
//      "akka.stream.impl.streamref.StreamRefsProtocol$RemoteStreamCompleted" = java
    }

    // force serialization even for local messages
//    serialize-messages = on

    allow-java-serialization = off
    warn-about-java-serializer-usage = on
  }

  coordinated-shutdown {
    terminate-actor-system = on

    run-by-jvm-shutdown-hook = on
    run-by-actor-system-terminate = on

    // hard exit of JVM (using System.exit)
    exit-jvm = on
  }

  remote {
    artery {
      enabled = on
      transport = tcp // prefer tcp over aeron-udp
      canonical.hostname = ${distod.host}
      canonical.port = ${distod.port}

      // Bind to a NIC at a different address (useful for Docker, NATs, ...)
      // If canonical and bind addresses are different, then network configuration that relays communications from
      // canonical to bind addresses is expected.
      bind.hostname = ${distod.host}
      bind.port = ${distod.port}

      // large message channel
      large-message-destinations = [
        "/user/partition-replicator/**"
      ]
      advanced {
        maximum-large-frame-size = 2 MiB
        large-buffer-pool-size = 32
        outbound-large-message-queue-size = 256
      }
    }

    log-received-messages = off
    log-sent-messages = off

    watch-failure-detector {
      implementation-class = "akka.remote.PhiAccrualFailureDetector"
      heartbeat-interval = 1s
      threshold = 10.0
      max-sample-size = 200
      min-std-deviation = 100ms
      acceptable-heartbeat-pause = 10s
      expected-response-after = 1s
    }
  }

  cluster {
    min-nr-of-members = 1

    role {
      leader.min-nr-of-members = 1
      follower.min-nr-of-members = 0
    }
    roles = [
      ${distod.system-role}
    ]

    seed-nodes = [
      "akka://"${distod.system-name}"@"${distod.leader-host}":"${distod.leader-port}
    ]
    seed-node-timeout = 5s
    // Disable join retry by specifying "off"
    retry-unsuccessful-join-after = 10s

    // Pluggable support for downing of nodes in the cluster.
    // If this setting is left empty the `NoDowning` provider is used and no automatic downing will be performed.
    downing-provider-class = ""

    // This will terminate the ActorSystem when the cluster extension is shutdown
    run-coordinated-shutdown-when-down = on

    // how often should the node send out gossip information?
    gossip-interval = 1s

    // discard incoming gossip messages if not handled within this duration
    gossip-time-to-live = 2s

    // how often should the leader perform maintenance tasks?
    leader-actions-interval = 1s

    failure-detector {
      implementation-class = "akka.remote.PhiAccrualFailureDetector"
      heartbeat-interval = 1s
      threshold = 8.0
      max-sample-size = 1000
      min-std-deviation = 100ms
      acceptable-heartbeat-pause = 3s
      monitored-by-nr-of-members = 5 // default: 9
      expected-response-after = 1s
    }
  }
}
